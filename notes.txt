Goal: Generic ObjectOriented Game Enigne

Edge cases:
    pawn, en passant
    castling
    
Other weird things: 
    pawn-promotion
    king must move out of check
    king cannot move into check
    other peices can't move in a way that puts king in check

figure out inheritance of a king(piece)

1/17

store board position with 1=white vs 2=black

two_by_ones()

try filtering pieces by b_white property

get_available_moves()
    eliminate own piece blocks
    allow opponent piece capture

1/18

x  spaces = X is not implemented -> king is not implemented
   pawn move is not implemented
    upacross(spaces = 2, only_up = True)

   filter_blocking can give all the available from all possible
x  filter_by_blocking()

1/19


finish implementing all piece movements

make a turn-engine
    x make random moves
    x allow input to control a player

king and enpassant-vulnerable-pawn are needed as enums on board

Long-Term:
    calculate all get_diags get_across etc for each position into a lookup table
    can cache available moves to each piece and use in next turn


why does the debug break in VScode on print IOError?
    > print rook_moves
    > IOError: [Errno 2] No such file or directory
    everyone since Fall Creator updates has this:
        https://github.com/Microsoft/vscode/issues/36630

board should store edge cases:
     king_can_castle, rook_can_castle, en_passant_vulnerable [0,1,,0,0]...

    -> so that, piece.get_available_moves(board) is full evaulation
       not: piece.get_available_moves(board, white's pawns, etc...)

1/22

    todo:
        en passant
        castling
        player move cant put his king in check
        
        promotion
        available_moves when player in check
        >hint should display moves helpfully

1/23

    need to clear en passant
    write tests for enpassant in main
    castling
    pretty-print available moves

1/26

    tests for castling
    clear_castling
    bug for calling a castle ambiguous with king step left
    bug for both castles being available when one is False, the "any()" line is culprit?
    tests for clear castling
    test for main() by loading moves
    tests for castling

1/27

    x modfiy_castle()
    x test this out
    add tests to main 
        add instructions in Select A Move section
        add 

    Takeaways: data_struct[player] vs data_struct[1-int(player)]
    is a very easy mistake to make and shows why you need getter'instead
    of modifying the property "by hand".


1/28

    as i realized, checkmate detector is not difficult, it is only:
        -available_moves [where king not in check] = {} ("empty set")
        -check_flag = True
    -> so the real heart of the game is calc'ing is_king_in_check

    modular idea: what if board.data was a numpy array? smaller mem and faster?

    #NOTE - how to get out of check? all moves filtered by king_in_check
            #   but how to handle killing the checking piece?

    TODO:
        refactor data_by_player
    x    add named_tuple for move
        make player 0,1 not true,False
        make board the first argument in TurnStage functions

1/29

    TODO:
        add to Game() init_board, init_player 
           to allow testing specific situations

        add exit code for available moves
        add exit code for total number of moves to allow random play

        build tests for king in check in specific situations

        add perf_test.py to time play()

            add a bool to game to turn on/off filter_king_check()
            check the difference in time

            add perf_test_log to GameLog to collect granular timing
               data and additional info at each step

        build analyze_perf_test to analyze num_moves vs time_compute, etc.

    Ahh so optimal is O(n) * c where c is in [1,4]

    there are multiple optimizations:
        
        instead of copying the board, just set different positions,
        and then set them back as you exit function. (or is that even needed?) 
            (this could be wrong for en passant situations, 
                so dont run this optimize if this is so )

        how about "piping" moves from get_available -> filter_check
            this involves async in py3?

        using numpy instead of list of list
        using a 64char string instead of a list

        using superking instead of all opponent's pieces

        pre-computation+lookup for piece.get_moves() instead of on-the-spot calc

    so the initial abstraction of piece kills opponents piece regardless of rank
    breaks down here, as the king is special. we already knew that with check_flag 
    but that is poor because a. it's arduous to compute move_yourself_into_check 
    in O(n^2) and b. it doesnt capture the idea of moving so as to place opponent 
    in check.

    Ah, but none of the atomic-moves overlap thus the move_type and move can be parsed
    after exiting blocking_piece() at the bottom of get_available()

    Playful aside: like in poker with 'Hand' as a concept, 'check' is an ambiguous
    and overused concept in chess.

    TODO

        add board.get_pos_value(pos) and refactor
        add put_in_check also using mirror
        write non encapsulated
        apply yield in select spots
        create a modularized perf_test
        add more insturctions to see larger n
        build a n_available_moves log into GameLog and record during perf_test
        how to do reflective class.getattr()
            -> if so get to class_move_types in one calc?
            should be named piece_movetypes_spaces

    1/31

        investigate pieces.pop() issue?
        

    a better name for super-king is mirror-piece: "if it can kill you, you can kill it"
    or an anti-king: "can attack only when in check"
        this is like a queen plus a horse but can't kill pawns head-on
        and cant kill king except directly adjacent
        but it doesn't neccesarily move unless attacking.
        ahh but what if oppoent piece cant kill it because doing so would put 
        himself in check? can the mirror-piece still attack opponent, except with king
        where he cant kill it because that would put him in check
        

    2/8

    TODO

        x PoC with turn_times in perf_test
        x basic check_optimal implementation
        copy.deepcopy on get_log_X() as they are list of lists
        x perf_test of using bypass mirror calc in possible_check_optimal() 
        tests to figure out if optimal works for all cases naive does
        does check_optimal work with pawns? prolly not right now

        think about how to mutate board instead of apply_rule
            do you need pos0? or pos1?
            do you need to account for kill_piece popping? - (yes)
            and how does this change in check_opponent vs 
                dont_move_self_into_check

            so i think you need pos0 only on dont_move_self_into_check,
                (for everything execpt castling, and king moves)
                but you need pos1 only on opponent_check. True?

            so essentially if MOVE_CODE == 'regular' then do mirror, 
            otherwise do naive could work

        how do you isolate get_available_moves() time from full turn loop?

        Try @classmethod
        https://julien.danjou.info/blog/2013/guide-python-static-class-abstract-methods

    2/9

        x Print out turn_time
        try to remove copy(board) from inner loop
        do a plt
        do a regression
        first we need more game-data, need a save function from manual mode
        need a way to return game state data in  board, like in-check to tests

        BUGS
            x moving R or K after castling does not work
            x filter_copy_apply_4 is fast but doesnt pass 3 test

    2/12

        BUGS
            x can't use raw_input in git-bash or in vscode-python-debug (just hangs)
            fixed by loading root dir of exercises and picking up integrated shell settings?
            this way, python debug stdout loads in 'Terminal' tab under 'python debug' mode,
            otherwise it loads in 'Debug Console'

                Fixes:
                    GitBash: prepend with 'winpty'
                        >winpty python file.py
                        >python -i

                    VSCode: In Debug section, get a launch.json settings
                        chose 'Python Terminal (integrated)' or
                        'Python Terminal (external).

        TODO:
            x add in player-in-check
            use piece.alive=False in naive-check-filter
            need to use a fork for filter_king_in_check when opponents pieces < 4 (?)
            x pass the pytest's that are broken 
                (? they arent croken currently,turn of c_apply_4 by default ?)
            Better prettyprint for 'hint'
            x more tests for check
            Find way to view size of memory of the python program

            there is still not alive=False function in mutate_pieces
                -> does this create errors?
                It seems once the enum is no longer on the board, it won't
                get picked up by mirror-king, so it should work except enpassant
                which has already been ruled out.

        Questions:
            Does get_possible_check_optimal take into account pawns?
                I think so because (movetype.diagonal, 1) in in Mirror.class_movements()
                    but how does this handle direction?

            How does modify castling propert work for rooks?

    2/15

        TODO
            record game outcome
            checkmate bug
                bring in board/pieces from an exit
            build a unified Board+Pieces Data Structure

            Build up a way to log when the check_cache is in use, use that
            to compare perf in before vs. after:

                e.g. 20% of the time the turn can use the cache, and in this time
                it cuts down on average 75% of the turn time. Therefore average
                per turn processing is lowered by 15%

    2/16

        TODO
            PGN() class
            alphanum_instructions <- str(log.get_log_move())  play() <- pgn_instructions


    2/26

        TODO

            tests for perf_test.py 
            promotion functionalities + tests
            add promotion to log_move / parse_move
            test for profile_test.py
            remove test:basic or repair it


    3/16

        TODO

            promotion in TurnStage
                dy default it creates a queen, but you override to set a piece you want

            i think b_pawn in mirror functions is still not handled appropriately

            first add a test for succesful promotion under advance and capture

    3/19

        Notes

            To copy/paste in git/mingw:
                Copy: Shift + PgDn  (note: need to turn off 'fn')
                Paste: Shift + Ins  (note: need to turn off 'fn')

            How to mark, though?
        
        Questions

            x is move_type=promotion marker ahead of filter_king_in_check() ?
            x if so how do we filter it out?
            x Yes, it's ok: filter_by_blocking_move handles this

        Takeaways

            based on previous bug with castling, where king castled with an already
            captured rook, the promotion test finds multiple ways to probe the state
            and see if everything checks out.

        TODO

            Main need: handle pawns in king_in_check properly, build tests for that


    3/23

        TODO

            Fix pawn bug in king_in_check

            Setup tests to find any other ways that king_in_check_optimal is different
            from naive version

            Fix letter-numbers to conform to pgn: 
                in printout display and in interactive instructions

        In the Future:

            Start testing end-game return codes
            Start testing more pgn's 

    3/26

        TODOs
            x basecamp
            x test with pawns threatening king
            x how to run tests with/without castling
            x test with castling
                x eg castling into check by pawn
            x cleanup main and move seperate function calls to misc-script.py
            
            x start testing end-game conditions
            
            x need to test in_check more, not just filter_check
            
            also think about ways [standard] checkmate is ever different than
            len(filter_check(moves)) == 0?

            need to account for #1-0 comment in pgn

            need to test stalemate vs checkmate more

        Takeaways 

            Use a positive control when testing for negative results:
                e.g. when testing that you can't castle for test and verify
                that you can castle in other conditions and that you're verifying
                that is happening as seen in test_cant_castle_into_check_1()

    3/27
        
        TODOs
            
            refactor play() and kwargs names
                naive_check_filter
                dummy_deepcopy_filter
                opt_mutate_naive_check
                naive_mutate_opt_check
                opt_check_filter

        Grand Projets

            Analyze the perf-tradeoff of mirror vs naive in late game "low piece" situations
                to do this, you need to run a batch of games
                can look at a random-play game vs expert game

            Build the "cache" of opp_kill_moves
                analyze the perf-boost (or loss) as probability and a net

            Add numpy / str as board data Structure

            Add a combined piece+board data structure

            Score each move based on extensibly-definable-characteristics

            Build a pondering tree

            Analyze the size of each node
                can these be compressed?

    3/28

        x Get Kasparov games to run in batch:
            x fix pgn_instruct pop() bug
            x make sure the last move is included in pgn_instructs
            x when exiting play() before an endgame occurs, note the final player to have moved, its likely he won b/c the other guy resigned
            x finally, write and pass the batch_play test

        x Fix Game on Line 10 bug

        Add some unit tests for parse_pgn

        Would be nice to not return data calling play as function
        but from the game object itself.

        Fix A-G 1-8
            
        Nice to have a 0-7, 0-7 display as an option for debugging
        
        Then fix the A1 insturctions to 1A insturctions

        How to port tests to new style? an extra arg of b_legacy?

        Why don't my conditional break points work!!?
            but sometimes do?

        We can add "check indicator" to pgn_parse and verify our check that way

        Utlimately need a new dataset which plays the games thru mate for
        better testing

        RANDOM:
            can you solve hinomaru with soduku like data structure?
                
                this creates an almost closed-form / 'one-fell-swoop' /
                strict-computational-upper-bound form of search,
                compared to a randomly selecting, and pruning a tree.

                This has to do with "spacial-constraints"-space introduced by 
                soduku where rows,cols,9-squares form [exclusion] relationships between
                various squares, and thus means iterating across them less times.


        
    3/29

        x iron out errors found in batch_run

        need to import results from meta-data in GarryKasparov

        need to add check - '+' - in pgn's into data available for testing
        
        Really need to cleanup the git folder
            make sure to get your .vscode folder too

        Ultimately, refactoring will come with a little better test coverage,
        cleaner git, cleaner repo, and more structured repo, and maybe some unit tests.

            Also well want to know how to use git to rename files

            Well rename the functions and kwargs for algo

            As we move into pondering, well need to restructre some helper classes
            like Mirror.

        Another optimization is to break out of move-set when the
        first move in that move-set is invalid. E.g. moving the knight
        somewhere puts your king in check then moving him anywhere puts you incheck.
        
        
        Takeaways
            A lot of these recent bugs could have been fixed with unit-testing
            e.g. 
                pgn_parse disambig isdigit
                pgn_parse queen side castling carries wrong move data structure
                king_check_optimal doesnt shield
            I'm saved by having a wealth of already-QA'd example cases to test against
            but this won't always be the case.

    3/30

        TODOs
        10-11:30 do some misc bugs

            A1 -> 1A
                rebench tests?
                add a pos type annotations; 0-7 on rows and cols

            meta-data in .pgn

            check '+' from pgn

            fix global find in vscode
            
            final cleanup:
            Move Incompatibility | line_i:  1456
            game.i_turn:  15
            On PGN turn:  8  Player:  White
            Move Incompatibility | line_i:  1457
            game.i_turn:  2
            On PGN turn:  1  Player:  Black
            Move Incompatibility | line_i:  1458
            game.i_turn:  19
            On PGN turn:  10  Player:  White

        Grand Projects

            BatchTests module (separate file):
                 - verify move permissibility
                (this only verifies were not overly liberal
                but we still might be too conservative)
                 - verify check by turn
                 - verify checkmate
                 - verfiy stalemate
                
                need to find more data-sources, esp. for checkmate

            Computational Cost of various move-scoring routines
                e.g. to know if your move puts opponent in check
                you need to perform calc and this make them 10% more
                expensive than the baseline

            Need to sample existing games to do stats on computation-time
            in "real game" scenarios.

            Are doublet_instructions faster to run than pgn_instructions?

            to run through verified pgn's we dont need filter_check or is_check
            so we should have a master switch to turn that all off
            ultimately all the check functions will need to be centralized
            when introducing check_cache

            There is a probabilistic way to make naive check faster:
                - since we return early on 1st check we find, we optimally start
                with "the most likely to cause check" piece and proceed in order
                that way, e.g. "bishop checked me last turn, bet he's the one to do
                it this turn"
                - still you have to do it for each of your moves, but you can exit on
                ideally the first opponent piece.
                - can you even do this with mutator() efficiency?

            Can we put this python engine into Xamarin? How about if we strip
            any extra packages, and compile it to iron-python? then "to dll" then
            into android?
        
        3/31

            build a batch test to verify correctness
                first on check_schedule
                then on: mate_turn
                then on:
                    last player = outcome
                    or
                    stalemate-outcome match
                        well need to add more functionality here.

            Use JSON for building data

            Also add some sqlite in here, true?

            Refactoring Ideas
                in play(), building test_data in a function of Game.
                    reset_test() at top of play.

        4/2

            build GameSchema into a full data-management class
            read/write to json

            we havent verified all check is correct yet: do that

            still need interactive mode out_log as a pgn

            build example TruePositive kickouts from verify() functions
                e.g. add a move incompatibility to a pgn
                and show how it kicksout. bonus for prettyprint display
                with meta data: e.g turn 39, white's move, etc... and
                then what move was requested.

            TODO

                strip \n from pgn_s_instructions in parse_pgn

            Refactoring play()

                top of the func should be put into a method and instead
                pieces = self.pieces
                board = self.board
                player = self.player
                check_test_exit:
                    build_test_data(data, in , here)  [1-liner]
                    continue
                rename to check_test_exit_pre_move
                          check_test_exit_post_move

                build 

                refactor filter_king_in_check names

            Grand Projects

                import stockfish and use calls into it

                Create a MoveSchema

                Create a ComputationalTimeSchema

        4/3

            TODO

                merge game-schema-add branch
                add notes to master
                create move-instruction bugs
                create kickouts_log
                fix move-instruction bugs
                    (can verify validity thru other chess apps)
                find out if cruft like fn0.pgn is being used
                git rm unnec cruft

                grid is wrong on printout (1-8 -> 8-1)
                    does this effect anything else?

                try vs code with terminal on the side

                add filter_data
                add test_filter_data
                add specific_turn in verify
                build printout turn function
                and build kickouts for check_schedule

                build verify_move_availability
                build true_negative unit test for verify_move_availibility
                build kickouts_move_availability.txt
                investigate kickouts
                
                wrap manual_check_schedule_match in decorator
                and manual_move_availability

                apply this command to data/tests/test_dummy_1.txt
                (as it changes each time pytest is run b/c its destroyed recreated
                with a new parse-time)
                git update-index --assume-unchanged src/file/to/ignore

        4/4

            naive_check can be made more efficient by only processing
            pawn attacks, not pawn moves

            add a board rotation to see from black-pov

            still need to work on end_game routine
                only_king_50_moves logging

            add gamelog for regular vs exotic moves

            still need to work on

            need more pgn datasets, or to extend them further

            TODO

                x get into branch refactor-game

                x put top of play into initialize()

                x run initialize by default()

                x refactor main kwargs

                x refactor other kwargs

                add check_for_check kwrarg to control 
                calling is_king_in_check()

                x refactor function names and import names

                refactor check_test_exit / check_test_exit_moves

                refactor build_test_data
                    rebench any tests

                handle load() / save() to persist game

                [break]

                hello world on perf_test

                send perf_tests data to data/perf_tests

                build indexed samples of games to run in perf_tests

                log perf_tests to sqlite

                build some perf_test unit tests
                    e.g test_strict_opt_time: opt < 3.5x baseline
                        test_lax_opt_time: opt < 4.3x baseline
                        we can keep running tests untill strict is reached

                build GarryKasparov_clean.xpgn

                add meta-data to pgn_to_xpgn
                    current commit hash
                    parse options requested

            Grand Projects

                Build an api at basic_engine level which allows apps to interface
                with Game. The M in MVC.

    4/5

        WANTED

            Decorators examples
                perf_test
                batchverify manual_batch cntl+c

            yield examples
            
            sqlite
                stick .xpgns into it
                log each turn's game move

            git merge conflicts
                create them, solve them

            python3
                two_to_three
                perf_test diff

        Grand Projects

            Build the basic_engine into multi-platforms

                home-rolled [flask] http / html web-service game

                pyQt - basic Qt gui app

                kivy
                    android
                    ios
                    other?

                iron python library? with .net gui MVC?`

            Build the AI component

            Build a centralized workspace for computational analysis


        TODO

            hello profile_test
            output to data dir
            ipython?

            we want a regression on MOVES['regular'], output to 

        4/9

            TODO

                switch to master
                make changes to main:
                    eliminate check code
                    add an argument for player_in_check

                now get a v1 profile_test.py and data without
                check_for_check, and make sure data is in the right place.
                eliminate the data in the wrong place.


                how to printout profile-test with no misc text?

                build v2 and unit tests

        4/10

            TODO
 
                x do unit tests for get_ncalls
                x add a bypass of non-regular moves for time comparison
                    do in both filter_check_opt and filter_check_naive
                x now do runprofiles2 with bypass on
                x do a unit test of bypass

                now, combine run_profiles into modularized function
                    and with this change fn list structure

                    __main__ doesnt need to import Game
                    test does need to import Game

                    handle not having b_bypass in test functions

                Look at cproifle cum to see if anything fishy is holding us back

                Build batch verifies which look at num_moves with bypass on and off

                BUG? fn is a global not a local 'file_names' is run_profile()


            Grand Projects

                write an api for openai gym

        4/11

            x cancel out tests
            write unit tests for TestArgs
            unittests for build_cmd_str
            build __main__ to do some function, controlled by argparse

            Larger Projects

                can you substitute deepcopy on board or pieces with copy?

                there is the application of late game situations with low pieces
                where filter_check_naive may outperform, find those.

                "Troitsky Line"
                https://en.wikipedia.org/wiki/Two_knights_endgame#Two_knights_versus_pawn

                PyChess
                https://en.wikipedia.org/wiki/PyChess

                Webapp two people can play

                three-fold-repetition rule 
                    (a draw)
                    (even if not sequential e.g. perpetual check)

                VSCode - "macros" for multiple view changes?
                    toggle line number
                    toggle panel
                    toggle sidebar and sidebar size
                    hide an editor panel to go half screen
                https://code.visualstudio.com/docs/getstarted/userinterface

        4/13

            TODO

                create run_profiles2
                run_profiles -> run_profiles_legacy`
                uncomment the tests below
                refactor for new run_profile

        4/15

            Meetup

                Neal
                Lilian 
                Yong

        5/1

            Lets ship profile_test:

                First, get it running:
                    need to build function which ties together:
                        build_cmd_str
                        runctx
                        handles filenames, etc
                    does TestArgs class even use base_args?
                        are they accounted for in get_data()?


                Then make sure commented-out batch tests run
                    do these offer clues to getting a first run?

                Finally use some command line args

                More TODOs on profiling:
                    [ ] Test names to CamelCase (as kwargs are snake_case)
                    [ ] json dumps on parameters for cmd line calling

            TODO

                [x] run some pytests - still working?
                [x] reproduce printout bug
                [x] get windows spring update
                [x] verify the bug is fixed
                still need to turn off autocomplete for .txt files

            
            Grand Projects

                Look at scenarios where naive is faster than opt

                    build a test where you init with data_from_printout,
                    here, just assess ncalls, e.g.
                        K+Q+R vs. k+p


                Validate the Troitsky line
                
        5/6

            longgame isnt triggering a change in ncalls, so what's up?
                lets delete the files and see

        5/23

            [x] delete all data/profile files; does it work?
            [x] run all commands avail from cmd line, note them in commented code

            [x] a long game is only profiling first move; why? b/c thye are pgn insturcts
            [x] fix test 1 in profile_test
            [x] limit --current to just one profile
            [?] need to refactor for different experiment types
            [ ] use ncalls to display a less verbose display

        5/25

            [x] --current still shows one-move-game below
            [x] FN[i] is not the way to do it

            [x] finish documenting rest of functionality.
            [x] add cmds to docs/cmds-list.txt
            [x] cleanup and merge branch

            Stuff not completed in profile_test module (Maybe Later?):
                [ ] a unit test on  test_bypass_irregular_less_moves
                [ ] adding irregular_moves into main argparse functions
                [ ] adding a return_ncalls type printout
                [ ] a way to look at other functions than just get_available_moves
              
            [x] cleanup directory of unused files
            [ ] write some notes of whats needed next


        Review of the worksapce as of 5/25:

            Little things:

                [x] alter the vscode fileexplorer to hide:
                    .cache (from pytest)
                    .ipynb_checkpoints
                    .code-workspace
                [x] get your settings and keyboard_vs up into a git repo
                [ ] TurnStage(513): b_bypass implemented in filter_check_naive()
                    appears to be wrong
                        fix this when implemnting final touches on profile_test
                [ ] How to update params on batchverify; add this to cmds-list.txt
                [ ] Can finally delete basic:print2() and remove its references

            
            Medium Things:
            
                [ ] Next step is rewriting(?)/running perf_test
                    [ ] Need some kind of baseline saved in data/
                    [ ] different game logging attributes
                    [ ] we're headed towards switching b/w naive and opt
                        at some low piece count on board. Think with that in mind.

                [ ] Have a proof of concept of altering engine code and re-baselining

                [ ] How to get sensible width terminal is vscode?

                [ ] start implementing blog post of vscode customization

            Major things:

                There's half a dozen concepts like Enums and static-typing that I'd like to
                implement into this.
                        This will require going to py3
                        Also it would be nice to get timing data baseline in py2 first
                    [ ] Let's get a list of things that we want to implement

                There's other libraries we want to use like stockfish:

                There's the whole 'select_move' module to build out

                There's the kivo/web-app etc build stuff to add
                    and the MVC concept into Game.play()

            5/27
            
            perf_test.py 

            [x] bug - second test does not print

                [ ] add a unit test after fix
                [x] add appropriate s_instructions

            Cleaup:
            [x] add clarifying comments
            [x] summary - all the styles run via commenting out
            [x] are play() kwargs correct in select_function()? no, fix!
            [x] ss (set line 20) needs a short move
            [ ] remove header print in interpret_turn_time_data()
            [x] opt_game_log (381) is mis-named
            [ ] why does var3 take less  time than opt

            Add Features:
            [x] select_function takes s_insturction as arg
            [x] game_init in separate function
            [x] play 0th move init'd ?
            [x] need a way to do pgn_instructions
                [x] but pgn requires compute time to deduce, should have a 
                    conversion called pgn->A1 pre-timing
            [ ] interpert_xxx_data() saves number data as string?
            [ ] print out meta-data header for reports
                [ ] s_instructions
                [ ] num of plies
                [ ] comments from each s_test e.g. "this is naive, it run naive_filter"
            [x] s_tests returned by named function
            [x] Currently timing Game's init() not just play()
                [x] change this with decorators?
                [x] use indv turn time summing, and take the difference
            [x] Currently perf_test times get_log_data() at end of play()
            
            Add Analysis:
            [x] add a check_for_check analysis
            [x] add a warm-up and cool-down analysis
            [x] an init analysis, calling game constructor before
                [x] also calling test_exit_moves=1 on play() before.
            [x] a pgn vs s_instruction analysis
            [ ] add num_irregluar to turntime logging and reporting
            [ ] add num pieces
            [ ] add b_bypass analysis ?
            [ ] add num_king_moves
            

            Module Architecture:
            [ ] add argparse to run these different styles
                [ ] how to bring in a string of s_instructions
            [ ] add an importable callable function that logs to data
                    and has variables for s_instruction, s_test, etc..
            [ ] function to write reports to files instead of console
                [ ] build a data directory
            
            Advanced Concepts:
            [ ] how to handle "zero" turn times?
                [x] - demonstrate how to get them
                        n=1, b_turn_time should do it

            [ ] Ultimately, this data can be used to build a regression:
                
                TurnTime ~ A + B*num_moves
                TurnTime ~ A + B1*Regular_num_moves + B2*Irregular_num_moves
                TurnTime ~ B1*num_my_pieces*num_your_moves
                ...etc...

                [ ] Log a lot of the data
                [ ] Find a way to aggregate the logged data into regression form
                [ ] Run a regression in R
                [ ] Compare SSE to a priori results discovered via profile_test


        5/28

            Add unit tests:
            [ ] that basic demo works
            [ ] that init_time > 0

            Cleanup:
            [x] add decorator to replace load_init
                [x] remove load_ in select_function()

        5/29

            [x] pgn_conversion in utils
            [x] pgn_conversion in perf_test
            [ ] batch perf_test
                [ ] log_schema for output
            [ ] adding variables to gamelog
            [ ] architecture: run first logging all the variables
                then second time logging turn times
                [ ] how to tie the two runs together?
            [ ] add a current timing benchmark utility:
                see if a change in engine has a statistically significant
                change in perf
                [ ] multiple game types
                [ ] log in multiple computational situations for the variance
                    in 
                [ ] warm-up phase
                [ ] git based comparison

        5/30

            [ ] Analysis on b_full_log: True vs. False
                how much time does it take to log?

            [ ] Idea for wram-up and baselining, do some non-custom known actions
                like adding 1M items to a list, summing it, etc...
                    -This will see the natural temporal variation on your 
                     computing/python env


        Other TODOs

            [ ] a test runner to run all the tests
            [ ] profile_test is using wrong A1 format on line 290
            [ ] conversion functions:
                [x] A1-movelog <-> PGN-movelog
                [ ] Get board state at certain move nums
                    [ ] output as a python / json format
                    [ ] output as a console
                    [ ] how to handle board_state
                    [ ] output move_log as pgn
            [ ] build random game play data
                [ ] control the randomness to lean towards capture, etc...
                [ ] build randomness from low-piece-initial-state
            [ ] Get the whole app running in linux env
                [ ] WSL, etc?
                [ ] path utilities, etc...


        6/12

            There are ways to defeat the filter_check algo?
                what if opponent piece could kill you but is pinned to his own king?
                This counter-case doesn't work, you can't move into where an oppoent
                piece can kill you next turn, even if that leaves him in check the next
                turn.
            Maybe something about putting him in check?

        6/13

            Need to build batch() in perf_test

                [ ] Build a Schema for results
                    [ ] output it to json
                    [ ] give it an extension name
                    [ ] load it from json
                
                [ ] Get an ipython notebook plotting the data
                    [x] notebook plotting random data
                    [ ] notebook reading a schema and 
                    [ ] do a basic regression
                    [ ] pandas
                    [ ] aggregation if needed

                [ ] Misc Cool Stuff
                    [ ] assertions amidst code, with exceptions

            There's something wrong with schema: different batch runs of N-trials need
            separate 

        6/15

            [ ] add unittests of all flagged commands
            [ ] separate utils.xpgn_to_pgn into separate file, along with its tests
                [ ] and it references throughout repository
            [ ] use sqlite and ORM to get TAS into
            [ ] how to build warning messages into these utilites, e.g. pytest as example
            [ ] how to handle double, decimals, etc.

        OK, the whole point of the TimeAnalysisSchema, and perf_test is to generate
        data to run regressions on turn time, and create different conditions to reveal
        how

        It's also a model of how to build processing pipelines:
            class based schema
            scenarios / "forcings" - as input files
            a blackbox with logging multi-dim output
            need to align the inputs and output logs and find the relationships

            




        HOWTOs

            to view the board while debugging:
                do into play() on stack
                create a Display class: 
                >display = Display()
                invoke function:
                >display.print_board_letters(pieces)

            
            use git stashing/branching for this repair:

                stash changes (made on master)
                >git stash save
                >git stash list
                stash@{0}: WIP on master: 39adbe1 notes basecamp for bug fixing stashes and commits
                
                build a new branch 'fix-test-and-engine-bug'
                git checkout -b fix-test-and-engine-bug

                switch to branch
                (already done)

                verify all tests are (incorrectly) passing
                (yes)
                
                pop stash changes to get fix for test bug
                >git stash apply

                also copy stash changes in notes to notes in branch
                (manually)

                manually apply fix into indv test cases
                adding game.reset_test() into tests

                run tests to reveal which tests break
                >pytest -vv main.py

                break these tests into a separate file
                >failing-tests.py

                verify you can run just those tests with test-runner
                >pytest -vv failing-tests.py

                make a commit here to identify which tests were incorrect
                >git add main.py failing-tests.py notes.txt
                >git commit -m '[message]'
                >git push origin fix-test-and-engine-bug

                now go into engine and fix bug
                (done)

                verify all tests pass after fix: both ones that were broken
                and ones working before - "that you didnt cause a regression"

                remove separate test file
                >rm failing-tests.py
                >git rm -r failing-tests.py

                commit this into branch
                >git push origin fix-test-and-engine-bug

                merge branch into master:
                on github, do merge pull request through UI
                now, on git client
                >git checkout master
                >git status  (seems like youre good but youre not)
                >git pull origin master
                (now youre good)

            
            How to split up a git repo:

                https://help.github.com/articles/splitting-a-subfolder-out-into-a-new-repository/

                clone repo locally into a temp
                run git prune
                git init remotely
                change local's remote to new init'd repo
                push the change to new remote(with -u)
                now locally, clone that new remote repo into a fresh local dir


            Also helpful, git cheatsheet
            https://gist.github.com/hofmannsven/6814451

                git mv filename newfilname
                git mv folder1 folder2
                (all file system cp / del is included)

                rm -f .git/index.lock   (when you can't add anything)
                


        Takeaways

            There is the notion of move or turn characteristics / features.
            Here we build an engine which minimizes computation time, and thus
            construct the bare number of features available, 

            THIS WAS ALL BAD SPECULATION DOWN A RABBIT HOLE

                e.g. not checking for check at the end/beginning of the turn.

                There might be some weird/theoretical cases where castling is a 
                valid escape sowe can identify those individually and test for 
                them in a sub-module?

                The unintuitive notion this exercises exposes is "Don't move a piece such
                that it puts yourself in check" is a rather estoric rule, but it is the only
                rule neccessary for computing: legal_moves, and end_game.
                This is because people don't build a list of all possible legal spaces each
                turn, instead they focus on five or six, and thus the verbal "check" helps
                them refocus their search.
                This also suggests that an AI would do well to limit its considerations
                to ~5 moves each turn, not every legally permissible one.

            Actually there is a good optimization to do here:
                If the king has len(opp_kill_moves) == 0 at the beggining of turn, 
                when you check is_king_in_check() then don't bother doing a mirror
                except with the move is associated with king.
                -> TODO: get a bunch or real life games and see when this comes 
                        into effect

                NOPE - this is all wrong speculation again; mirror_flag uses board
                pos to assess blocking pieces. 
                
                Still, there seems something to notion that opponents pieces
                don't move during your turn, thus some kind shortcut?

                    Maybe 'bypass' the first piece of yours in filter_blocking()
                    and cache that pos as in list_calc_needed when another piece
                    is validated as a threat. Then only run 
                    mirror on a move where pos0 is in list_calc_needed. A "moving
                    away a blocker" type move; implied is you can never add to possibility
                    of being in check based on where you end up.

                To consider: enpassant is the one move where pos1 != kill_pos, and that
                             oppoent pawn could be blocking check, with no piece there
                             to replace it.
                

                        
        
    Takeaway 1/30

        check out Mirror class for a pattern for building up a list of 
        increasingly large and informative tuples. But could this be accomplished
        in the other direction for each move, go through all the steps...?

        can't you just build list<-map() for each step      

        overall, a pretty good way to build 'a mirror image piece in OO chess engine'
        but YMMV. why:

            - encapsulation of functions, even staticmoves dont crowd into other modules

            - it represents one esoteric, isolated, confusing concept - that these 
            three pieces of information - move_type, move_paces, piece_class - can
            allow you to deduce if king is in check (or any piece in general is threatend)
            and this doesnt get applied or depended on anywhere else.            

            - it allows you to build up a naming motif in a completely enclosed scope

            - it allows you to build up a processing motif e.g 
              self.var2 = [func(x) for x in self.var]

            - shows you clearly what are inputs and outputs to this processing, and if
              any special order is needed

            - modularizes comments to its atomic concern: you can't about Hypothetical
              code changes that might affect this instruction while proc procedurally




    

    Idea for perf analysis:

    BUT: the below doesnt work becaused it has to occur for each-piece-move tuple
        same as iterating of opponent's possible moves. Instead we need a 
        list of positions on the board that help keep king out of check for non-king moves
        these dont include horse moves because horse is never blocked.
        Only when one of these pieces is proposed moved could the king be threatened.
        Note: this only occurs when a piece MOVES AWAY, not where it moves TO.
        This set of own-players pieces, calcd before each turn, is what hypo-king
        helps us calculate.

    it will be a lot faster to model is_king_in_check 
    without iterating across all opponents pieces possible moves 
    which runs in  O(piece-moves^2) or O(piece-moves * 2) (?)
    instead create a King-Hypothetical class which has all other pieces'
    moves and see if it "can kill" an opponents piece of the class that
    has the move type, which should be on the order of O(piece-move) 
    little higher than Queen's O(piece-move).
    You might also be able to cache the result, and only recalculate
    if a certain piece "assuring" it remains in position is moved.

    you can test the bigO-time by changing BOARD_WIDTH = 9,10,11,...
    you can test practical perf by taking random moves, or importing
    saved chess games and running total time it takes to calc all
    get_available_moves() using each method

    1/27 Thoughts:
        - it is O(n^2) if you think of piece-moves, and the most naive algo
         - to make the board wider, you need to handle castling better with board_width param

Takeaways:

    1/27
    software engineering and team-code practices become important at the point where
    one nice abstraction no longer encapsulates the whole requirements: in this case
    that occurs when enpassant and castling are added in. This requires enums and if/then
    logic processing

    Also, its true that available_moves, followed by end-game-conditions-check
    is the how to write these engines.

    instantiating the pieces is costly at each branch

    the correct level of abstraction for the Board is 
        piece vs. blank, 
        white-piece vs black-piece
        special-piece vs generic-piece. specials:
            king
            en-passant-vulnerable-pawn 
        ...nothing else needs to be considered at game-logic level, only
           further up at the stratgey-level.

    

    A board-move class holds dimensions of the board, the coloring and orietation, and
    the rules for the initial piece setup.
    Also, it holds the mathematical logic of the atomic moves:
        upacross [distance modifier] [w/wo player-direction-orientation e.g what is "move up"]
        diagonal [distance modifier] [w/wo player-direction-orientation]
        two_by_one
        

    The pieces then hold the business rules for which atomic move types they can perform and
    at what modification they can perform them, plus GameLedger modifications

        in addition to the Board is a Game-Ledger which tracks
            [king_can_castle | rook_can_castle]
            king_in_check
            turn_counter_while_solitary_king
            last_two_moves_tracker (for a 3-move-repeat-stalemate)
            pawn_advance_two can be held in the piece object

    Most rules are packed into available_moves routine
    
    Available_Moves_Player_P <- func(Board,Pieces,GameLedger)
        Available_Moves_i <- func(Piece_i,Board_current)
            <- filtered(king in check) Func(Board, Pieces)
               if GameLedger.check_flag
                    <- filtered(move-removes-check_flag)

    Then the strategy-module needs to consider the following info-blobs:
        Game board with pieces
        GameLedger
        Player_turn_current
        [turn_counter ?]
        ... everything else is derivative?
        
random thought: a mechanichal chess board is valuable to new variants of the rules that need
                inter-turn reshuffling of the pieces of display of available moves

        


